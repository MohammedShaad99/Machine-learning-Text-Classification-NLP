# Machine-learning-Text-Classification-NLP

# How to run??
1]. Install all the required libraries should be install. For example:- pip install pandas
2]. Provide the location of the dataset to the path variable in the program.

# A brief summary of the code

Initially, applied all the necessary libraries. Here, the data is stored in multiple text files inside the BBC folder which needs to be converted into a single CSV file with popper formating. The data sets are stored in a certain location and the link should be provided. The os.listdir() function will return all the folders from the path specified and stored in a list. The goal is to open the folder and read the content from the file and also the folder’s name should be stored in lists. These lists can be then converted into a data frame using pandas.


# Pre-processing:- 

The goal is to store the list in two columns so it becomes less complicated to perform tasks on it, the first column will contain the information regarding all the articles and the other one will display the categories of the article.

The text must not contain any unwanted characters. For this regular expression can be used and for each row, the function can be called. The function will perform the following tasks:-
* Converting the text to lower case so that no two same words appear in the document term matrix.
* Removing the text in between the square brackets, punctuations, digits, quotations, and any special characters. 
* Split text and perform lemmatization. It will reduce the word into dictionary root form. For example:-‘playing’ will be converted into ‘play’ and hence feature can be reduced. The data frame after applying this function.

# Choice of the feature:- 

The next step is to convert the data according to the feature.

* Machines tend to understand numbers better rather than words. So for converting numbers into words one of the most popular approaches is to use The Bag of Words. The bag of words could be converted in to document term matrix(which describes the frequency of a word occurring in a document) by using CountVectorizer and applying the fit_transform function.

* Another feature similar to CountVectorizer but much more accurate is TFIDF which also converts the data into a document term matrix but it selects features very accurately. However in this case the number of features that it selected were similar to the count-vectorizer.

* Bi-gram feature could be used and a document term matrix could be generated by either TFIDF or CountVectorizer. In bigram, it will consider two words and create a document term matrix. It generates 13805 features.

* All these three features are then combined by using the FeatureUnion function. By Combining all of these features, accuracy might likely be increased but surely the features would be increased.

# Feature selection:-

The best features based on their frequency in the text must be selected which would help in reducing the dimensionality of features and this could be achieved by using SelectKBest. After combining all the three features there were 84,731 columns and by using Kbest the dimensionality was reduced to 3000. This will prevent the model from overfitting and will also reduce the time required to train the model.

# Training and testing the model:-

To select the perfect model for training and testing, parameter tuning and model selection could be performed from the result.

* Model selection can be applied to select the best model based on its accuracy in which all the models are added in the dictionary and every model’s score is predicted and the best model could be selected based on the scores.

* Parameter tuning is performed on a few parameters of the model to obtain the most accurate model with their accurate parameters.
* The train and tests are separated and each fold is applied on a single iteration of the loop. Also, the loop is applied for model selection, the models are passed inside the GridSearchCV will fit all the models present inside the dictionary and that information could be extracted.
* Now, based on the accuracy and parameters the best model was printed, and manually from the few models, the most accurate model could be selected.
* Voting Classifier is a machine learning model that trains on various models and predicts based on aggregation. The voting parameter is set as ‘hard’ which indicates that it will estimate the output based on the majority of the output provided from the models inside the estimator’s parameter. The models provided inside the VotingClassifiers are LogisticRegression, RandomForestClassifier, MultinomialNB, SupportVectorMachine, and BernoulliNB. CrossValidation technique is applied to the data set with 5 folds. On each folds the data set (X1) is divided into a certain amount of train and test data. On this data, VotingClassifer can be applied to train, predict and find the accuracy. VotingClassifer provides the highest accuracy but it takes a long time to train the data.


# Predication accuracy 
* The average accuracy is 97.71%.
* The macro average precision is 97.78%.
* The macro average recall is 97.61%.
* The macro average f1-score is 97.68%


